package main

import (
	"bytes"
	"embed"
	"encoding/json"
	"flag"
	"fmt"
	"html/template"
	"io"
	"io/fs"
	"io/ioutil"
	"net"
	"net/http"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"sort"
	"strconv"
	"strings"
	"sync"
	"sync/atomic"
	"syscall"
	"time"

	connect3270 "github.com/3270io/3270Connect/connect3270"
	"github.com/3270io/3270Connect/sampleapps/app1"
	app2 "github.com/3270io/3270Connect/sampleapps/app2"

	"github.com/gin-gonic/gin"
	"github.com/shirou/gopsutil/cpu"
	"github.com/shirou/gopsutil/mem"
)

const version = "1.7.5"

const (
	cpuHistoryLimit              = 120
	memHistoryLimit              = 120
	workflowDurationHistoryLimit = 500
	inMemoryLogLimit             = 500
	dashboardCleanupInterval     = time.Minute
	liveStatsHistoryLimit        = 12
)

var errorList []error
var errorMutex sync.Mutex

// Configuration holds the settings for the terminal connection and the steps to be executed.
type Configuration struct {
	Host            string
	Port            int
	OutputFilePath  string `json:"OutputFilePath"`
	WaitForField    bool   `json:"WaitForField,omitempty"`
	Steps           []Step
	Delay           float64 `json:"Delay,omitempty"`
	Token           string  `json:"Token,omitempty"`
	InputFilePath   string  `json:"InputFilePath"`
	RampUpBatchSize int     `json:"RampUpBatchSize"`
	RampUpDelay     float64 `json:"RampUpDelay"`
}

// Step represents an individual action to be taken on the terminal.
type Step struct {
	Type        string
	Coordinates connect3270.Coordinates
	Text        string
	Delay       float64 `json:"Delay,omitempty"`
}

func resolveTokenPlaceholder(original, token string) string {
	if !strings.Contains(original, "{{token}}") {
		return original
	}

	if token == "" {
		tokenWarningOnce.Do(func() {
			pterm.Warning.Println("Placeholder {{token}} detected in workflow text, but no token value was supplied.")
		})
		return original
	}

	return strings.ReplaceAll(original, "{{token}}", token)
}

var (
	configFile       string
	injectionConfig  string
	rsaToken         string
	showHelp         bool
	runAPI           bool
	apiPort          int
	concurrent       int
	headless         bool
	verbose          bool
	verboseFailures  bool
	runApp           string
	runtimeDuration  int
	lastUsedPort     int
	startPort        int
	tokenWarningOnce sync.Once
)

var dashboardStarted bool

// Global counters for metrics.
var totalWorkflowsStarted int64
var totalWorkflowsCompleted int64
var totalWorkflowsFailed int64

var dashboardPort int

var activeWorkflows int
var mutex sync.Mutex

var timingsMutex sync.Mutex
var workflowDurations []float64
var workflowDurationSum float64
var workflowDurationCount int64

var metricsMutex sync.Mutex
var cpuHistory []float64
var memHistory []float64
var totalCPUUsage float64
var totalCPUSamples int64
var totalMemUsage float64
var totalMemSamples int64
var lastCPUUsage float64
var lastMemUsage float64
var lastCleanupRun time.Time

var showVersion = flag.Bool("version", false, "Show the application version")
var startDashboard = flag.Bool("dashboard", false, "Start the dashboard and open the webpage")

var enableProgressBar bool

var runAppPort int
var metricsConfigFilePath string
var metricsOutputFilePath string
var workflowTimeout int
var showConnectionErrors bool

type LogEntry struct {
	PID        string    `json:"pid"`
	Parameters string    `json:"parameters"`
	Log        string    `json:"log"`
	Timestamp  time.Time `json:"timestamp"`
}

var inMemoryLogs []LogEntry
var logMutex sync.Mutex

//go:embed templates/dashboard.gohtml
//go:embed templates/static/*
var dashboardTemplateFS embed.FS

var dashboardTemplate *template.Template

var programStart time.Time

func appendLimitedFloat(slice *[]float64, value float64, limit int) {
	*slice = append(*slice, value)
	if limit <= 0 {
		return
	}
	if len(*slice) > limit {
		*slice = (*slice)[len(*slice)-limit:]
	}
}

func appendLimitedLog(slice *[]LogEntry, entry LogEntry, limit int) {
	*slice = append(*slice, entry)
	if limit <= 0 {
		return
	}
	if len(*slice) > limit {
		excess := len(*slice) - limit
		*slice = (*slice)[excess:]
	}
}

func appendLimitedString(slice *[]string, value string, limit int) {
	*slice = append(*slice, value)
	if limit <= 0 {
		return
	}
	if len(*slice) > limit {
		*slice = (*slice)[len(*slice)-limit:]
	}
}

func recordWorkflowDuration(duration float64) {
	timingsMutex.Lock()
	appendLimitedFloat(&workflowDurations, duration, workflowDurationHistoryLimit)
	workflowDurationSum += duration
	workflowDurationCount++
	timingsMutex.Unlock()
}

func getAverageWorkflowDuration() float64 {
	timingsMutex.Lock()
	defer timingsMutex.Unlock()
	if workflowDurationCount == 0 {
		return 0
	}
	return workflowDurationSum / float64(workflowDurationCount)
}

func getAverageCPUUsage() float64 {
	metricsMutex.Lock()
	defer metricsMutex.Unlock()
	if totalCPUSamples == 0 {
		return 0
	}
	return totalCPUUsage / float64(totalCPUSamples)
}

func getAverageMemoryUsage() float64 {
	metricsMutex.Lock()
	defer metricsMutex.Unlock()
	if totalMemSamples == 0 {
		return 0
	}
	return totalMemUsage / float64(totalMemSamples)
}

func getLastCPUUsage() float64 {
	metricsMutex.Lock()
	defer metricsMutex.Unlock()
	return lastCPUUsage
}

func getLastMemoryUsage() float64 {
	metricsMutex.Lock()
	defer metricsMutex.Unlock()
	return lastMemUsage
}

func maybeCleanupDashboardArtifacts() {
	metricsMutex.Lock()
	shouldSkip := time.Since(lastCleanupRun) < dashboardCleanupInterval
	if !shouldSkip {
		lastCleanupRun = time.Now()
	}
	metricsMutex.Unlock()
	if shouldSkip {
		return
	}
	dashboardDir := dashboardMetricsDir()
	// Trigger cleanup by reading and evaluating metrics files.
	readDashboardMetrics(dashboardDir)
}

func init() {
	flag.StringVar(&configFile, "config", "workflow.json", "Path to the configuration file")
	flag.StringVar(&injectionConfig, "injectionConfig", "", "Path to the injection configuration file")
	flag.StringVar(&rsaToken, "token", "", "RSA token value to substitute for {{token}} placeholders")
	flag.BoolVar(&showHelp, "help", false, "Show usage information")
	flag.BoolVar(&runAPI, "api", false, "Run as API")
	flag.IntVar(&apiPort, "api-port", 8080, "API port")
	flag.IntVar(&concurrent, "concurrent", 1, "Number of concurrent workflows")
	flag.BoolVar(&headless, "headless", false, "Run go3270 in headless mode")
	flag.BoolVar(&verbose, "verbose", false, "Run go3270 in verbose mode")
	flag.BoolVar(&verboseFailures, "verboseFailures", false, "Log failures even when verbose is off")
	flag.IntVar(&runtimeDuration, "runtime", 0, "Duration to run workflows in seconds")
	flag.StringVar(&runApp, "runApp", "", "Select which sample 3270 app to run ('1' or '2')")
	flag.IntVar(&runAppPort, "runApp-port", 3270, "Port for the sample 3270 app")
	flag.IntVar(&startPort, "startPort", 5000, "Starting port for workflow connections")
	flag.IntVar(&workflowTimeout, "workflowTimeout", 0, "Hard timeout per workflow in seconds (0 to disable)")
	flag.BoolVar(&showConnectionErrors, "showConnectionErrors", false, "Treat connection failures as errors and report them")
	flag.IntVar(&dashboardPort, "dashboardPort", 9200, "Port for the dashboard server")
	flag.BoolVar(&enableProgressBar, "enableProgressBar", false, "Enable progress bar and hide INFO log messages")

	// Set up pterm with a funky theme
	pterm.DefaultSection.Style = pterm.NewStyle(pterm.FgCyan, pterm.Bold)
	pterm.Info.Prefix = Prefix{Text: "INFO", Style: pterm.NewStyle(pterm.BgBlue, pterm.FgWhite)}
	pterm.Error.Prefix = Prefix{Text: "ERROR", Style: pterm.NewStyle(pterm.BgRed, pterm.FgWhite)}
	pterm.Success.Prefix = Prefix{Text: "SUCCESS", Style: pterm.NewStyle(pterm.BgGreen, pterm.FgBlack)}
	pterm.Warning.Prefix = Prefix{Text: "WARNING", Style: pterm.NewStyle(pterm.BgYellow, pterm.FgBlack)}

	if err := os.MkdirAll("logs", 0755); err != nil {
		pterm.Error.Println("Failed to create logs dir - universe says no:", err)
	}

	var err error
	dashboardTemplate, err = template.ParseFS(dashboardTemplateFS, "templates/dashboard.gohtml")
	if err != nil {
		pterm.Error.Println("Dashboard template parsing went kaput:", err)
	} else {
		//pterm.Success.Println("Dashboard template loaded - ready to rock!")
	}
}

func storeLog(message string) {
	logMutex.Lock()
	defer logMutex.Unlock()
	pid := os.Getpid()
	args := os.Args[1:]
	parameters := strings.Join(args, " ")

	logEntry := LogEntry{
		PID:        strconv.Itoa(pid),
		Parameters: parameters,
		Log:        message,
		Timestamp:  time.Now(),
	}
	appendLimitedLog(&inMemoryLogs, logEntry, inMemoryLogLimit)

	logFilePath := filepath.Join("logs", fmt.Sprintf("logs_%d.json", pid))
	file, err := os.OpenFile(logFilePath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
	if err != nil {
		pterm.Error.Println("Log file opening failed - send help:", err)
		return
	}
	defer file.Close()

	encoder := json.NewEncoder(file)
	if err := encoder.Encode(logEntry); err != nil {
		pterm.Error.Println("Log encoding broke - computers hate me:", err)
	}
}

// getExecutablePath resolves the most up-to-date 3270Connect binary.
func getExecutablePath() string {
	exeName := "3270Connect"
	if runtime.GOOS == "windows" {
		exeName += ".exe"
	}

	// Build candidate list: prefer repo/dist outputs (CI), then local builds, then
	// the currently running binary (when it already is 3270Connect).
	candidates := make([]string, 0, 6)
	if cwd, err := os.Getwd(); err == nil {
		candidates = append(candidates,
			filepath.Join(cwd, "dist", exeName),
			filepath.Join(cwd, exeName),
		)
	}
	if runningPath, err := os.Executable(); err == nil {
		baseDir := filepath.Dir(runningPath)
		if filepath.Base(runningPath) == exeName {
			candidates = append(candidates, runningPath)
		}
		candidates = append(candidates,
			filepath.Join(baseDir, exeName),
			filepath.Join(baseDir, "dist", exeName),
		)
	}

	for _, candidate := range candidates {
		if fileExists(candidate) {
			return candidate
		}
	}

	// Fallback to relative paths for environments that expect the legacy layout.
	if runtime.GOOS == "windows" {
		return "./3270Connect.exe"
	}
	return "./3270Connect"
}

func fileExists(path string) bool {
	info, err := os.Stat(path)
	return err == nil && !info.IsDir()
}

func loadConfiguration(filePath string) *Configuration {
	//spinner, _ := pterm.DefaultSpinner.Start("Loading config - hold onto your hats!")
	if connect3270.Verbose {
		pterm.Info.Printf("Loading configuration from %s\n", filePath)
	}
	configFile, err := os.Open(filePath)
	if err != nil {
		pterm.Error.Printf("Error opening config file at %s: %v", filePath, err)
		os.Exit(1)
	}
	defer configFile.Close()
	config := Configuration{
		WaitForField: true, // default to waiting after Connect unless disabled in config
	}
	decoder := json.NewDecoder(configFile)
	err = decoder.Decode(&config)
	if err != nil {
		pterm.Error.Printf("Error decoding config JSON: %v", err)
	}
	if config.RampUpBatchSize <= 0 {
		config.RampUpBatchSize = 10
	}
	if config.RampUpDelay <= 0 {
		config.RampUpDelay = 1.0
	}
	err = validateConfiguration(&config)
	if err != nil {
		pterm.Error.Printf("Invalid configuration: %v", err)
	}
	//spinner.Success("Config loaded - we‚Äôre golden!")
	return &config
}

func loadInputFile(filePath string) ([]Step, error) {
	spinner, _ := pterm.DefaultSpinner.Start("Loading input file - fingers crossed!")
	if connect3270.Verbose {
		pterm.Info.Printf("Loading input file: %s\n", filePath)
	}
	data, err := ioutil.ReadFile(filePath)
	if err != nil {
		spinner.Fail("Input file read failed - disk gremlins:", err)
		return nil, fmt.Errorf("error reading input file: %v", err)
	}
	if connect3270.Verbose {
		pterm.Success.Printf("Successfully read input file: %d bytes\n", len(data))
	}
	var steps []Step
	steps = append(steps, Step{Type: "Connect"})
	if connect3270.Verbose {
		pterm.Info.Println("Added initial Connect step")
	}
	lines := strings.Split(string(data), "\n")
	for idx, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}
		if connect3270.Verbose {
			pterm.Info.Printf("Processing line %d: %s", idx+1, line)
		}
		if strings.HasPrefix(line, "yield ps.sendKeys") {
			key := strings.TrimPrefix(line, "yield ps.sendKeys(")
			key = strings.TrimSuffix(key, ");")
			key = strings.Trim(key, "'")
			stepType := ""
			switch key {
			case "ControlKey.TAB":
				stepType = "PressTab"
			case "ControlKey.ENTER":
				stepType = "PressEnter"
			case "ControlKey.F1":
				stepType = "PressPF1"
			case "ControlKey.F2":
				stepType = "PressPF2"
			case "ControlKey.F3":
				stepType = "PressPF3"
			case "ControlKey.F4":
				stepType = "PressPF4"
			case "ControlKey.F5":
				stepType = "PressPF5"
			case "ControlKey.F6":
				stepType = "PressPF6"
			case "ControlKey.F7":
				stepType = "PressPF7"
			case "ControlKey.F8":
				stepType = "PressPF8"
			case "ControlKey.F9":
				stepType = "PressPF9"
			case "ControlKey.F10":
				stepType = "PressPF10"
			case "ControlKey.F11":
				stepType = "PressPF11"
			case "ControlKey.F12":
				stepType = "PressPF12"
			case "ControlKey.F13":
				stepType = "PressPF13"
			case "ControlKey.F14":
				stepType = "PressPF14"
			case "ControlKey.F15":
				stepType = "PressPF15"
			case "ControlKey.F16":
				stepType = "PressPF16"
			case "ControlKey.F17":
				stepType = "PressPF17"
			case "ControlKey.F18":
				stepType = "PressPF18"
			case "ControlKey.F19":
				stepType = "PressPF19"
			case "ControlKey.F20":
				stepType = "PressPF20"
			case "ControlKey.F21":
				stepType = "PressPF21"
			case "ControlKey.F22":
				stepType = "PressPF22"
			case "ControlKey.F23":
				stepType = "PressPF23"
			case "ControlKey.F24":
				stepType = "PressPF24"
			default:
				stepType = "FillString"
			}
			step := Step{Type: stepType, Text: key}
			steps = append(steps, step)
			if connect3270.Verbose {
				pterm.Info.Printf("Added step: %s with text: %s\n", stepType, key)
			}
		} else if strings.HasPrefix(line, "yield wait.forText") {
			parts := strings.Split(line, ",")
			if len(parts) >= 2 {
				text := strings.TrimPrefix(parts[0], "yield wait.forText('")
				text = strings.TrimSuffix(text, "'")
				position := strings.TrimPrefix(parts[1], "new Position(")
				position = strings.TrimSuffix(position, ");")
				posParts := strings.Split(position, ",")
				if len(posParts) == 2 {
					row, errRow := strconv.Atoi(strings.TrimSpace(posParts[0]))
					column, errCol := strconv.Atoi(strings.TrimSpace(posParts[1]))
					if errRow != nil || errCol != nil {
						if connect3270.Verbose {
							pterm.Warning.Printf("Error parsing position in line %d - numbers hate me\n", idx+1)
						}
						continue
					}
					step := Step{
						Type: "CheckValue",
						Coordinates: connect3270.Coordinates{
							Row:    row,
							Column: column,
							Length: len(text),
						},
						Text: text,
					}
					steps = append(steps, step)
					if connect3270.Verbose {
						pterm.Info.Printf("Added CheckValue step: text '%s' at (%d,%d), length %d\n", text, row, column, len(text))
					}
				}
			}
		} else if strings.HasPrefix(line, "// Fill in the first name at row") || strings.HasPrefix(line, "// Fill in the last name at row") {
			parts := strings.Split(line, " ")
			if len(parts) >= 8 {
				row, errRow := strconv.Atoi(parts[6])
				column, errCol := strconv.Atoi(parts[9])
				if errRow != nil || errCol != nil {
					if connect3270.Verbose {
						pterm.Warning.Printf("Error parsing coords in line %d - math is hard\n", idx+1)
					}
					continue
				}
				if idx+1 < len(lines) {
					nextLine := strings.TrimSpace(lines[idx+1])
					if strings.HasPrefix(nextLine, "yield ps.sendKeys") {
						key := strings.TrimPrefix(nextLine, "yield ps.sendKeys(")
						key = strings.TrimSuffix(key, ");")
						key = strings.Trim(key, "'")
						step := Step{
							Type: "FillString",
							Coordinates: connect3270.Coordinates{
								Row:    row,
								Column: column,
							},
							Text: key,
						}
						steps = append(steps, step)
						if connect3270.Verbose {
							pterm.Info.Printf("Added FillString step: text '%s' at (%d,%d)\n", key, row, column)
						}
					}
				}
			}
		}
	}
	steps = append(steps, Step{Type: "Disconnect"})
	if connect3270.Verbose {
		pterm.Info.Println("Added final Disconnect step")
		pterm.DefaultTable.WithHasHeader().WithData(TableData{
			{"Step", "Type", "Text", "Row", "Column", "Length"},
			{"", "", "", "", "", ""}, // Separator
		}).Render()
		for i, step := range steps {
			pterm.DefaultTable.WithData(TableData{
				{strconv.Itoa(i), step.Type, step.Text, strconv.Itoa(step.Coordinates.Row), strconv.Itoa(step.Coordinates.Column), strconv.Itoa(step.Coordinates.Length)},
			}).Render()
		}
	}
	spinner.Success("Input file loaded - we‚Äôre cooking with gas!")
	return steps, nil
}

func runWorkflow(scriptPort int, config *Configuration) error {
	e := connect3270.NewEmulator(config.Host, config.Port, strconv.Itoa(scriptPort))
	return runWorkflowWithEmulator(e, config, time.Time{})
}

func runWorkflowWithEmulator(e *connect3270.Emulator, config *Configuration, overallDeadline time.Time) error {
	// Check if shutdown was requested before starting workflow execution
	if connect3270.ShutdownRequested() {
		return nil // Graceful stop: do not count as started or failed
	}
	// If the run-wide deadline has already passed, skip starting a new workflow.
	if !overallDeadline.IsZero() && time.Now().After(overallDeadline) {
		return nil
	}
	scriptPortLabel := e.ScriptPort
	startTime := time.Now()
	var workflowDeadline time.Time
	if workflowTimeout > 0 {
		workflowDeadline = startTime.Add(time.Duration(workflowTimeout) * time.Second)
	}
	atomic.AddInt64(&totalWorkflowsStarted, 1)
	if connect3270.Verbose {
		pterm.Info.Printf("Starting workflow for scriptPort %s\n", scriptPortLabel)
	}
	storeLog(fmt.Sprintf("Starting workflow for scriptPort %s", scriptPortLabel))
	mutex.Lock()
	activeWorkflows++
	mutex.Unlock()
	defer func() {
		mutex.Lock()
		activeWorkflows--
		mutex.Unlock()
	}()
	e.Host = config.Host
	e.Port = config.Port

	// Always start from a clean session to avoid reusing stale emulator state between pooled runs.
	_ = e.Disconnect()
	defer e.Disconnect()
	tmpFileName := config.OutputFilePath
	cleanupTempFile := false
	if tmpFileName == "" {
		tmpFile, err := ioutil.TempFile("", "workflowOutput_")
		if err != nil {
			return handleError(err, fmt.Sprintf("Temp file creation failed - disk‚Äôs playing hide and seek: %v", err))
		}
		tmpFileName = tmpFile.Name()
		tmpFile.Close()
		cleanupTempFile = true
	}
	defer func() {
		if cleanupTempFile {
			os.Remove(tmpFileName)
		}
	}()
	if err := e.InitializeOutput(tmpFileName, runAPI); err != nil {
		return handleError(err, fmt.Sprintf("Output init failed - setup's cursed: %v", err))
	}
	workflowFailed := false
	connectFailed := false
	var steps []Step
	var err error
	if config.InputFilePath != "" {
		steps, err = loadInputFile(config.InputFilePath)
		if err != nil {
			return handleError(err, fmt.Sprintf("Input file load crashed - file has gone rogue: %v\n", err))
		}
	} else {
		steps = config.Steps
	}

	stepDelay := secondsToDuration(config.Delay)
	for idx, step := range steps {
		if workflowFailed {
			break
		}
		if !workflowDeadline.IsZero() && time.Now().After(workflowDeadline) {
			workflowFailed = true
			addError(fmt.Errorf("workflow timed out after %ds", time.Since(startTime)/time.Second))
			break
		}
		if connect3270.ShutdownRequested() {
			break
		}
		if idx > 0 && stepDelay > 0 {
			time.Sleep(stepDelay)
		}
		err := executeStep(e, step, tmpFileName, config.Token)
		if err == nil && step.Type == "Connect" && config.WaitForField {
			waitErr := e.WaitForField(time.Second)
			if waitErr != nil {
				err = waitErr
			}
		}
		if err != nil {
			if err.Error() == "shutdown requested" {
				break // Graceful stop: do not count as failure
			}
			if step.Type == "Connect" {
				connectFailed = true
				if showConnectionErrors {
					addError(err)
				}
				break // Stop executing further steps when connection could not be established
			} else {
				workflowFailed = true
				addError(err)
				if verboseFailures {
					msg := fmt.Sprintf("Workflow failure on scriptPort %s at step %d (%s): %v", scriptPortLabel, idx+1, step.Type, err)
					storeLog(msg)
					pterm.Error.Println(msg)
				}
			}
		}
	}

	duration := time.Since(startTime).Seconds()
	recordWorkflowDuration(duration)

	if workflowFailed {
		atomic.AddInt64(&totalWorkflowsFailed, 1)
	} else if connectFailed {
		if showConnectionErrors {
			msg := fmt.Sprintf("Workflow for scriptPort %s failed to connect; not counted as workflow failure", scriptPortLabel)
			storeLog(msg)
			if connect3270.Verbose {
				pterm.Warning.Println(msg)
			}
		}
	} else {
		if connect3270.Verbose {
			storeLog(fmt.Sprintf("Workflow for scriptPort %s completed successfully", scriptPortLabel))
		}
		atomic.AddInt64(&totalWorkflowsCompleted, 1)
	}
	return nil
}

func secondsToDuration(seconds float64) time.Duration {
	if seconds <= 0 {
		return 0
	}
	return time.Duration(seconds * float64(time.Second))
}

func runAPIWorkflow() {
	if connect3270.Verbose {
		pterm.Info.Println("Starting API server mode - buckle up!")
	}
	connect3270.Headless = true
	gin.SetMode(gin.ReleaseMode)
	r := gin.Default()
	r.SetTrustedProxies(nil)
	r.POST("/api/execute", func(c *gin.Context) {
		workflowConfig := Configuration{WaitForField: true}
		if err := c.ShouldBindJSON(&workflowConfig); err != nil {
			sendErrorResponse(c, http.StatusBadRequest, "Invalid request payload - JSON‚Äôs drunk", err)
			return
		}
		if workflowConfig.Token == "" && rsaToken != "" {
			workflowConfig.Token = rsaToken
		}
		tmpFile, err := ioutil.TempFile("", "workflowOutput_")
		if err != nil {
			pterm.Error.Println("Temp file creation failed - disk‚Äôs napping:", err)
			sendErrorResponse(c, http.StatusInternalServerError, "Failed to create temp file", err)
			return
		}
		defer tmpFile.Close()
		tmpFileName := tmpFile.Name()
		defer os.Remove(tmpFileName)
		scriptPort := getNextAvailablePort()
		e := connect3270.NewEmulator(workflowConfig.Host, workflowConfig.Port, strconv.Itoa(scriptPort))
		err = e.InitializeOutput(tmpFileName, true)
		if err != nil {
			sendErrorResponse(c, http.StatusInternalServerError, "Output init failed - setup‚Äôs cursed", err)
			return
		}
		stepDelay := secondsToDuration(workflowConfig.Delay)
		for idx, step := range workflowConfig.Steps {
			if idx > 0 && stepDelay > 0 {
				time.Sleep(stepDelay)
			}
			if err := executeStep(e, step, tmpFileName, workflowConfig.Token); err != nil {
				sendErrorResponse(c, http.StatusInternalServerError, fmt.Sprintf("Step '%s' failed - oof", step.Type), err)
				e.Disconnect()
				return
			}
		}
		outputContents, err := e.ReadOutputFile(tmpFileName)
		if err != nil {
			sendErrorResponse(c, http.StatusInternalServerError, "Output read failed - file‚Äôs shy", err)
			return
		}
		e.Disconnect()
		c.JSON(http.StatusOK, gin.H{
			"returnCode": http.StatusOK,
			"status":     "okay",
			"message":    "Workflow executed successfully - high five!",
			"output":     outputContents,
		})
	})
	apiAddr := fmt.Sprintf("localhost:%d", apiPort) // Bind to localhost
	pterm.Success.Printf("API server rocking on %s - let‚Äôs roll!\n", apiAddr)
	if err := r.Run(apiAddr); err != nil {
		pterm.Error.Printf("API server crashed - send coffee: %v\n", err)
	}
}

func executeStep(e *connect3270.Emulator, step Step, tmpFileName string, token string) error {
	switch step.Type {
	case "InitializeOutput":
		return e.InitializeOutput(tmpFileName, runAPI)
	case "Connect":
		return e.Connect()
	case "CheckValue":
		expected := resolveTokenPlaceholder(step.Text, token)
		value, err := e.GetValue(step.Coordinates.Row, step.Coordinates.Column, step.Coordinates.Length)
		if err != nil {
			return err
		}
		value = strings.TrimSpace(value)
		if value != strings.TrimSpace(expected) {
			return fmt.Errorf("CheckValue failed. Expected: %s, Found: %s", expected, value)
		}
		return nil
	case "FillString":
		text := resolveTokenPlaceholder(step.Text, token)
		if step.Coordinates.Row == 0 && step.Coordinates.Column == 0 {
			return e.SetString(text)
		}
		return e.FillString(step.Coordinates.Row, step.Coordinates.Column, text)
	case "AsciiScreenGrab":
		return e.AsciiScreenGrab(tmpFileName, runAPI)
	case "PressEnter":
		return e.Press(connect3270.Enter)
	case "PressTab":
		return e.Press(connect3270.Tab)
	case "WaitForField":
		timeout := time.Second
		if step.Delay > 0 {
			timeout = time.Duration(step.Delay * float64(time.Second))
		}
		return e.WaitForField(timeout)
	case "Disconnect":
		if err := e.Disconnect(); err != nil {
			// Disconnect failures often mean the emulator is already gone; don't fail the workflow for that.
			msg := fmt.Sprintf("Disconnect ignored: %v", err)
			if connect3270.Verbose {
				pterm.Warning.Println(msg)
			} else {
				storeLog(msg)
			}
			return nil
		}
		return nil
	case "PressPF1":
		return e.Press(connect3270.F1)
	case "PressPF2":
		return e.Press(connect3270.F2)
	case "PressPF3":
		return e.Press(connect3270.F3)
	case "PressPF4":
		return e.Press(connect3270.F4)
	case "PressPF5":
		return e.Press(connect3270.F5)
	case "PressPF6":
		return e.Press(connect3270.F6)
	case "PressPF7":
		return e.Press(connect3270.F7)
	case "PressPF8":
		return e.Press(connect3270.F8)
	case "PressPF9":
		return e.Press(connect3270.F9)
	case "PressPF10":
		return e.Press(connect3270.F10)
	case "PressPF11":
		return e.Press(connect3270.F11)
	case "PressPF12":
		return e.Press(connect3270.F12)
	case "PressPF13":
		return e.Press(connect3270.F13)
	case "PressPF14":
		return e.Press(connect3270.F14)
	case "PressPF15":
		return e.Press(connect3270.F15)
	case "PressPF16":
		return e.Press(connect3270.F16)
	case "PressPF17":
		return e.Press(connect3270.F17)
	case "PressPF18":
		return e.Press(connect3270.F18)
	case "PressPF19":
		return e.Press(connect3270.F19)
	case "PressPF20":
		return e.Press(connect3270.F20)
	case "PressPF21":
		return e.Press(connect3270.F21)
	case "PressPF22":
		return e.Press(connect3270.F22)
	case "PressPF23":
		return e.Press(connect3270.F23)
	case "PressPF24":
		return e.Press(connect3270.F24)
	case "HumanDelay":
		humanDelay := secondsToDuration(step.Delay)
		if humanDelay <= 0 {
			return fmt.Errorf("HumanDelay requires a positive Delay value")
		}
		time.Sleep(humanDelay)
		return nil
	default:
		return fmt.Errorf("unknown step type: %s", step.Type)
	}
}

func sendErrorResponse(c *gin.Context, statusCode int, message string, err error) {
	if connect3270.Verbose {
		pterm.Info.Println("Sending error response - oopsie daisy!")
	}
	c.JSON(statusCode, gin.H{
		"returnCode": statusCode,
		"status":     "error",
		"message":    message,
		"error":      err.Error(),
	})
}

func printBanner() {

	clear()

	pterm.RenderBanner("3270Connect", "")
	pterm.Info.Println("Version: " + pterm.LightGreen(version))
	pterm.Info.Println("Website: " + pterm.LightGreen("https://3270.io"))
	pterm.Info.Println("Author: " + pterm.LightGreen("EyUp"))
	pterm.Info.Println("Runtime Environment: " + pterm.LightYellow(getExecutablePath()+" ") + pterm.White(strings.Join(os.Args[1:], " ")))
	pterm.Println()
}

func LaunchEmbeddedIfDoubleClicked() {
	if !*startDashboard {
		pterm.Warning.Println("Dashboard mode not enabled. Skipping embedded browser launch.")
		return
	}

	//if !isTerminal() {
	*startDashboard = true
	flag.Set("dashboard", "true")
	pterm.Info.Println("Launching dashboard in GUI mode (double-click detected)")

	// Start dashboard in background
	go runDashboard()

	// Give it time to start
	time.Sleep(1 * time.Second)
	storeLog("Starting dashboard mode - no terminal detected")
	// Launch the embedded browser
	openDashboardEmbedded()
	//}
}

func main() {
	flag.Parse()
	metricsConfigFilePath = configFile
	printBanner()
	// If no command-line parameters are provided, force dashboard mode.
	if len(os.Args) == 1 {
		*startDashboard = true
		flag.Set("dashboard", "true")
		pterm.Info.Println("No command-line parameters detected. Forcing dashboard mode.")
	}

	// If the dashboard is not started, the program will exit.
	//if *startDashboard {
	//	runDashboard()
	//	os.Exit(0)
	//}
	LaunchEmbeddedIfDoubleClicked()

	mutex.Lock()
	lastUsedPort = startPort
	mutex.Unlock()
	programStart = time.Now()
	if *showVersion {
		pterm.Info.Printf("3270Connect Version: %s \n", version)
		os.Exit(0)
	}
	if showHelp {
		pterm.Info.Printf("3270Connect Version: %s - Here‚Äôs the manual!\n", version)
		flag.Usage()
		os.Exit(0)
	}
	setGlobalSettings()
	if concurrent > 1 || runtimeDuration > 0 {
		go runDashboard()
	}
	go monitorSystemUsage()
	if runApp != "" {
		storeLog(fmt.Sprintf("RunApp selected: Sample App %s launched on port %d - PID: %d", runApp, runAppPort, os.Getpid()))
		switch runApp {
		case "1":
			app1.RunApplication(runAppPort)
			return
		case "2":
			app2.RunApplication(runAppPort)
			return
		default:
			pterm.Error.Printf("Invalid runApp value: %s - Did you mean 1 or 2?\n", runApp)
		}
	}

	// Prevent workflows from starting in dashboard-only mode
	if *startDashboard {
		pterm.Info.Println("Dashboard-only mode enabled. Skipping workflow execution.")
		select {} // Keep the program running for the dashboard
	}

	config := loadConfiguration(configFile)
	metricsOutputFilePath = config.OutputFilePath
	if rsaToken != "" {
		config.Token = rsaToken
	}
	if runAPI {
		runAPIWorkflow()
	} else {
		if concurrent > 1 || runtimeDuration > 0 {
			runConcurrentWorkflows(config, injectionConfig)

		} else {
			runWorkflow(lastUsedPort, config)
			printSingleWorkflowSummary()
		}
		if concurrent > 1 && dashboardStarted {
			pterm.Info.Printf("All workflows completed but the dashboard is still running on port %d. Press Ctrl+C to exit.", dashboardPort)
			select {}
		}
	}
	showErrors()
}

func setGlobalSettings() {
	connect3270.Headless = headless
	connect3270.Verbose = verbose
}

var stopTicker chan struct{}

type workflowWorker struct {
	id       int
	jobs     <-chan *Configuration
	wg       *sync.WaitGroup
	emulator *connect3270.Emulator
	deadline time.Time
}

func newWorkflowWorker(id int, jobs <-chan *Configuration, wg *sync.WaitGroup, deadline time.Time) *workflowWorker {
	return &workflowWorker{
		id:       id,
		jobs:     jobs,
		wg:       wg,
		emulator: connect3270.NewEmulator("", 0, ""),
		deadline: deadline,
	}
}

func (w *workflowWorker) start() {
	defer w.wg.Done()
	for cfg := range w.jobs {
		if cfg == nil {
			continue
		}
		// Check if shutdown was requested before starting new workflow
		if connect3270.ShutdownRequested() {
			if connect3270.Verbose {
				storeLog(fmt.Sprintf("Worker %d skipping workflow due to shutdown request", w.id))
			}
			continue
		}
		scriptPort := getNextAvailablePort()
		w.emulator.ScriptPort = strconv.Itoa(scriptPort)
		if connect3270.Verbose {
			storeLog(fmt.Sprintf("Worker %d using script port %d", w.id, scriptPort))
		}
		w.emulator.Host = cfg.Host
		w.emulator.Port = cfg.Port
		if err := runWorkflowWithEmulator(w.emulator, cfg, w.deadline); err != nil {
			storeLog(fmt.Sprintf("Worker %d workflow error: %v", w.id, err))
			if connect3270.Verbose {
				pterm.Error.Printf("Worker %d workflow error: %v\n", w.id, err)
			}
		}
	}
	_ = w.emulator.Disconnect()
}

func runConcurrentWorkflows(config *Configuration, injectionConfig string) {
	if runtimeDuration <= 0 {
		pterm.Warning.Println("Runtime duration must be greater than zero for concurrent execution.")
		return
	}
	connect3270.ResetShutdown()
	overallStart := time.Now()
	workerCount := concurrent
	if workerCount <= 0 {
		workerCount = 1
	}
	deadline := overallStart.Add(time.Duration(runtimeDuration) * time.Second)
	jobs := make(chan *Configuration)
	var workerWG sync.WaitGroup
	for i := 0; i < workerCount; i++ {
		workerWG.Add(1)
		worker := newWorkflowWorker(i, jobs, &workerWG, deadline)
		go worker.start()
	}

	var injectData []map[string]string
	if injectionConfig != "" {
		if _, err := os.Stat(injectionConfig); err == nil {
			var loadErr error
			injectData, loadErr = loadInjectionData(injectionConfig)
			if loadErr != nil {
				pterm.Error.Printf("Failed to load injection data: %v\n", loadErr)
				close(jobs)
				workerWG.Wait()
				return
			}
			pterm.Info.Printf("Loaded %d injection entries from %s\n", len(injectData), injectionConfig)
		} else {
			pterm.Warning.Printf("Injection file %s not found. Proceeding without injection.\n", injectionConfig)
		}
	}
	if len(injectData) == 0 {
		injectData = []map[string]string{{}}
	}

	var (
		multi       MultiPrinter
		durationBar *ProgressbarPrinter
		activeBar   *ProgressbarPrinter
		cpuBar      *ProgressbarPrinter
		memBar      *ProgressbarPrinter
	)
	const titleWidth = 30
	tickerInterval := time.Second
	if enableProgressBar {
		multi = pterm.DefaultMultiPrinter
		durationBar, _ = pterm.DefaultProgressbar.
			WithTotal(runtimeDuration).
			WithTitle(pterm.Sprintf("%-*s", titleWidth, "  Run Duration  ")).
			WithWriter(multi.NewWriter()).
			WithBarCharacter("-").
			WithBarStyle(pterm.NewStyle(pterm.FgCyan)).
			WithShowPercentage(true).
			WithShowCount(false).
			WithShowElapsedTime(true).
			Start()

		activeBar, _ = pterm.DefaultProgressbar.
			WithTotal(workerCount).
			WithTitle(pterm.Sprintf("%-*s", titleWidth, "Active vUsers")).
			WithWriter(multi.NewWriter()).
			WithBarCharacter("=").
			WithBarStyle(pterm.NewStyle(pterm.FgCyan)).
			WithShowPercentage(true).
			WithShowCount(false).
			WithShowElapsedTime(true).
			Start()

		cpuBar, _ = pterm.DefaultProgressbar.
			WithTotal(100).
			WithTitle(pterm.Sprintf("%-*s", titleWidth, "CPU Usage")).
			WithWriter(multi.NewWriter()).
			WithBarCharacter("=").
			WithBarStyle(pterm.NewStyle(pterm.FgGreen)).
			WithShowPercentage(true).
			WithShowCount(false).
			WithShowElapsedTime(true).
			Start()

		memBar, _ = pterm.DefaultProgressbar.
			WithTotal(100).
			WithTitle(pterm.Sprintf("%-*s", titleWidth, "Memory Usage")).
			WithWriter(multi.NewWriter()).
			WithBarCharacter("=").
			WithBarStyle(pterm.NewStyle(pterm.FgGreen)).
			WithShowPercentage(true).
			WithShowCount(false).
			WithShowElapsedTime(true).
			Start()
		pterm.Println()
	} else {
		pterm.Info.Println("Progress bar disabled. Live stats update every 5s (use -enableProgressBar for gauges).")
		tickerInterval = 5 * time.Second
	}

	deadline = overallStart.Add(time.Duration(runtimeDuration) * time.Second)

	stopTicker = make(chan struct{})
	go func() {
		ticker := time.NewTicker(tickerInterval)
		defer ticker.Stop()
		var lastFailCount int64
		for {
			select {
			case <-ticker.C:
				elapsed := int(time.Since(overallStart).Seconds())
				active := getActiveWorkflows()
				cpuVal := getLastCPUUsage()
				memVal := getLastMemoryUsage()
				started := atomic.LoadInt64(&totalWorkflowsStarted)
				completed := atomic.LoadInt64(&totalWorkflowsCompleted)
				failed := atomic.LoadInt64(&totalWorkflowsFailed)

				if enableProgressBar {
					if durationBar != nil {
						durationBar.Current = min(elapsed, runtimeDuration)
						if elapsed < runtimeDuration {
							durationBar.UpdateTitle(pterm.Sprintf("%-*s", titleWidth, fmt.Sprintf("Run Duration (%ds left)", runtimeDuration-elapsed)))
						} else {
							durationBar.UpdateTitle(pterm.Sprintf("%-*s", titleWidth, "Run Duration (Completed)"))
						}
					}
					if cpuBar != nil {
						cpuBar.Current = int(cpuVal)
					}
					if memBar != nil {
						memBar.Current = int(memVal)
					}
					if activeBar != nil {
						activeBar.Current = active
						activeBar.UpdateTitle(pterm.Sprintf("%-*s", titleWidth, fmt.Sprintf("Active vUsers (%d/%d)", active, workerCount)))
					}
					pterm.RenderProgressBars(activeBar, durationBar, cpuBar, memBar)
				} else {
					row := formatLiveStatsRow(time.Now(), elapsed, runtimeDuration, active, workerCount, started, completed, failed, cpuVal, memVal)
					if failed > lastFailCount {
						pterm.Error.Println(row)
						lastFailCount = failed
					} else {
						pterm.Info.Println(row)
					}
				}

				storeLog(fmt.Sprintf("Elapsed: %d, Active workflows: %d, CPU usage: %.2f%%, Memory usage: %.2f%%", elapsed, active, cpuVal, memVal))
			case <-stopTicker:
				return
			}

			if time.Now().After(deadline) {
				active := getActiveWorkflows()
				started := atomic.LoadInt64(&totalWorkflowsStarted)
				completed := atomic.LoadInt64(&totalWorkflowsCompleted)
				failed := atomic.LoadInt64(&totalWorkflowsFailed)
				if active == 0 && started == completed+failed {
					return
				}
			}
		}
	}()

	injectionCursor := 0
	rampDelay := time.Duration(config.RampUpDelay * float64(time.Second))
	if rampDelay <= 0 {
		rampDelay = time.Second
	}

	firstBatch := true
	stoppedScheduling := false
	for time.Now().Before(deadline) {
		if deadline.Sub(time.Now()) <= rampDelay {
			stoppedScheduling = true
			break // Don't launch new work when we're at/near the deadline; let in-flight finish.
		}
		availableSlots := workerCount - getActiveWorkflows()
		if availableSlots <= 0 {
			time.Sleep(rampDelay)
			continue
		}

		workflowsToStart := min(config.RampUpBatchSize, availableSlots)
		startedThisBatch := 0
		for startedThisBatch < workflowsToStart && time.Now().Before(deadline) {
			cfg := injectDynamicValues(config, injectData[injectionCursor])
			injectionCursor = (injectionCursor + 1) % len(injectData)
			jobs <- cfg
			startedThisBatch++
		}

		active := getActiveWorkflows()
		cpuVal := getLastCPUUsage()
		memVal := getLastMemoryUsage()
		storeLog(fmt.Sprintf("Scheduled %d workflows, active: %d, CPU: %.2f%%, MEM: %.2f%%", startedThisBatch, active, cpuVal, memVal))
		if active < workerCount {
			started := atomic.LoadInt64(&totalWorkflowsStarted)
			completed := atomic.LoadInt64(&totalWorkflowsCompleted)
			failed := atomic.LoadInt64(&totalWorkflowsFailed)
			combinedMsg := formatPowerupRow(time.Now(), overallStart, runtimeDuration, active, workerCount, startedThisBatch, started, completed, failed, cpuVal, memVal)
			infoIfBarsDisabled(combinedMsg)
			storeLog(combinedMsg)
		}

		if !firstBatch {
			time.Sleep(rampDelay)
		} else {
			firstBatch = false
		}
	}
	if stoppedScheduling {
		remain := deadline.Sub(time.Now())
		if remain < 0 {
			remain = 0
		}
		msg := fmt.Sprintf("Stopped scheduling new workflows to honor deadline (%.1fs remaining). Increase runtime or lower ramp-up to reach target concurrency.", remain.Seconds())
		infoIfBarsDisabled(msg)
		storeLog(msg)
	}

	if enableProgressBar {
		multi.Stop()
	}

	pterm.Success.Println("Run duration complete. Waiting for current workflows to finish...")
	connect3270.RequestShutdown()
	close(jobs)

	// Wait for workers with a grace period so we don't hang indefinitely.
	graceDone := make(chan struct{})
	go func() {
		workerWG.Wait()
		close(graceDone)
	}()
	select {
	case <-graceDone:
	case <-time.After(30 * time.Second):
		pterm.Warning.Println("Grace period elapsed while waiting for workers; forcing shutdown.")
	}
	storeLog("All workflows completed after runtimeDuration ended.")

	if stopTicker != nil {
		close(stopTicker)
	}

	if enableProgressBar {
		elapsed := int(time.Since(overallStart).Seconds())
		if durationBar != nil {
			durationBar.WithTotal(elapsed)
			durationBar.Current = elapsed
			const titleWidth = 30
			durationBar.UpdateTitle(pterm.Sprintf("%-*s", titleWidth, fmt.Sprintf("Run Duration (%ds elapsed)", elapsed)))
		}
		pterm.RenderProgressBars(activeBar, durationBar, cpuBar, memBar)
		pterm.Println()
	}

	avgCPU := getAverageCPUUsage()
	avgMem := getAverageMemoryUsage()
	avgWorkflowTime := getAverageWorkflowDuration()
	finalActive := getActiveWorkflows()
	finalStarted := atomic.LoadInt64(&totalWorkflowsStarted)
	finalCompleted := atomic.LoadInt64(&totalWorkflowsCompleted)
	finalFailed := atomic.LoadInt64(&totalWorkflowsFailed)

	clear()
	printBanner()
	pterm.Success.Println("All workflows wrapped up - Time for a victory lap!")
	elapsed := int(time.Since(overallStart).Seconds())
	pterm.DefaultSection.WithStyle(pterm.NewStyle(pterm.FgCyan)).Println("Run Summary - Performance Report")
	pterm.DefaultTable.
		WithHasHeader().
		WithLeftAlignment().
		WithData(TableData{
			{"Metric", "Value", "Status"},
			{"Total Workflows Started", fmt.Sprintf("%d", finalStarted), "üöÄ Launched"},
			{"Total Workflows Completed", fmt.Sprintf("%d", finalCompleted), "‚úÖ Done"},
			{"Total Workflows Failed", fmt.Sprintf("%d", finalFailed), func() string {
				if finalFailed > 0 {
					return "‚ùå Oof"
				}
				return "üéâ Perfect"
			}()},
			{"Final Active vUsers", fmt.Sprintf("%d/%d", finalActive, workerCount), func() string {
				if finalActive > 0 {
					return "‚ö†Ô∏è Oof"
				}
				return "üéâ Perfect"
			}()},
			{"Average CPU Usage", fmt.Sprintf("%.1f%%", avgCPU), cpuStatus(avgCPU)},
			{"Average Memory Usage", fmt.Sprintf("%.1f%%", avgMem), memStatus(avgMem)},
			{"Average Workflow Time", fmt.Sprintf("%.2fs", avgWorkflowTime), "‚è±Ô∏è Avg Duration"},
			{"Run Duration", fmt.Sprintf("%ds", elapsed), "‚úÖ Completed"},
		}).Render()

	summaryText := generateSummaryText(finalStarted, finalCompleted, finalFailed, finalActive, avgCPU, avgMem, avgWorkflowTime, float64(elapsed))
	summaryFile := filepath.Join("logs", fmt.Sprintf("summary_%d.txt", os.Getpid()))
	if err := os.WriteFile(summaryFile, []byte(summaryText), 0644); err != nil {
		pterm.Warning.Printf("Failed to save summary: %v\n", err)
	}

	storeLog("All workflows completed")
	updateMetricsFile()
}

// Helper functions for summary status
func cpuStatus(cpu float64) string {
	switch {
	case cpu < 50:
		return pterm.FgGreen.Sprintf("[OK]")
	case cpu < 80:
		return pterm.FgYellow.Sprintf("[WARM]")
	default:
		return pterm.FgRed.Sprintf("[HIGH]")
	}
}

func memStatus(mem float64) string {
	switch {
	case mem < 50:
		return pterm.FgGreen.Sprintf("[OK]")
	case mem < 80:
		return pterm.FgYellow.Sprintf("[WARM]")
	default:
		return pterm.FgRed.Sprintf("[HIGH]")
	}
}

func generateSummaryText(finalStarted, finalCompleted, finalFailed int64, finalActive int, avgCPU, avgMem, avgWorkflowTime, elapsed float64) string {
	var sb strings.Builder
	sb.WriteString("All workflows wrapped up - Time for a victory lap!\n\n")
	sb.WriteString("Run Summary - Performance Report\n")
	sb.WriteString(fmt.Sprintf("Total Workflows Started: %d\n", finalStarted))
	sb.WriteString(fmt.Sprintf("Total Workflows Completed: %d\n", finalCompleted))
	sb.WriteString(fmt.Sprintf("Total Workflows Failed: %d\n", finalFailed))
	sb.WriteString(fmt.Sprintf("Final Active vUsers: %d\n", finalActive))
	sb.WriteString(fmt.Sprintf("Average CPU Usage: %.1f%%\n", avgCPU))
	sb.WriteString(fmt.Sprintf("Average Memory Usage: %.1f%%\n", avgMem))
	sb.WriteString(fmt.Sprintf("Average Workflow Time: %.2fs\n", avgWorkflowTime))
	sb.WriteString(fmt.Sprintf("Run Duration: %.0fs\n", elapsed))
	return sb.String()
}

func formatLiveStatsRow(ts time.Time, elapsed, runtimeDuration, active, workerCount int, started, completed, failed int64, cpuUsage, memUsage float64) string {
	remaining := max(runtimeDuration-elapsed, 0)
	parts := []string{
		pterm.FgBlue.Sprintf("%s", ts.Format("15:04:05")),
		pterm.FgGreen.Sprintf("A:%d/%d", active, workerCount),
		pterm.FgCyan.Sprintf("S:%d", started),
		pterm.FgLightGreen.Sprintf("D:%d", completed),
		pterm.FgRed.Sprintf("F:%d", failed),
		pterm.FgYellow.Sprintf("E:%ds", elapsed),
		pterm.FgMagenta.Sprintf("R:%ds", remaining),
		pterm.FgCyan.Sprintf("C:%.1f%%", cpuUsage),
		pterm.FgMagenta.Sprintf("M:%.1f%%", memUsage),
	}
	return strings.Join(parts, " | ")
}

func formatPowerupRow(ts time.Time, overallStart time.Time, runtimeDuration int, active, workerCount, addedThisBatch int, started, completed, failed int64, cpuUsage, memUsage float64) string {
	elapsed := int(time.Since(overallStart).Seconds())
	remaining := max(runtimeDuration-elapsed, 0)
	parts := []string{
		pterm.FgBlue.Sprintf("%s", ts.Format("15:04:05")),
		pterm.FgGreen.Sprintf("A:%d/%d", active, workerCount),
		pterm.FgCyan.Sprintf("S:%d", started),
		pterm.FgLightGreen.Sprintf("D:%d", completed),
		pterm.FgRed.Sprintf("F:%d", failed),
		pterm.FgYellow.Sprintf("E:%ds", elapsed),
		pterm.FgMagenta.Sprintf("R:%ds", remaining),
		pterm.FgCyan.Sprintf("C:%.1f%%", cpuUsage),
		pterm.FgMagenta.Sprintf("M:%.1f%%", memUsage),
		pterm.FgLightGreen.Sprintf("RAMP +%d", addedThisBatch),
		pterm.FgYellow.Sprintf("GAP:%d", workerCount-active),
	}
	return strings.Join(parts, " | ")
}

func infoIfBarsDisabled(msg string) {
	if enableProgressBar {
		return
	}
	pterm.Info.Println(msg)
}

func infofIfBarsDisabled(format string, args ...interface{}) {
	if enableProgressBar {
		return
	}
	pterm.Info.Printf(format, args...)
}

func printSingleWorkflowSummary() {
	avgCPU := getAverageCPUUsage()
	avgMem := getAverageMemoryUsage()
	avgWorkflowTime := getAverageWorkflowDuration()

	// Capture final stats
	finalStarted := atomic.LoadInt64(&totalWorkflowsStarted)
	finalCompleted := atomic.LoadInt64(&totalWorkflowsCompleted)
	finalFailed := atomic.LoadInt64(&totalWorkflowsFailed)

	elapsed := int(time.Since(programStart).Seconds())

	pterm.Success.Println("Workflow completed - Time for a victory lap!")

	// Display summary report
	pterm.DefaultSection.WithStyle(pterm.NewStyle(pterm.FgCyan)).Println("Run Summary - Performance Report")
	pterm.DefaultTable.
		WithHasHeader().
		WithLeftAlignment().
		WithData(TableData{
			{"Metric", "Value", "Status"},
			{"Total Workflows Started", fmt.Sprintf("%d", finalStarted), "üöÄ Launched"},
			{"Total Workflows Completed", fmt.Sprintf("%d", finalCompleted), "‚úÖ Done"},
			{"Total Workflows Failed", fmt.Sprintf("%d", finalFailed), func() string {
				if finalFailed > 0 {
					return "‚ùå Oof"
				}
				return "üéâ Perfect"
			}()},
			{"Average CPU Usage", fmt.Sprintf("%.1f%%", avgCPU), cpuStatus(avgCPU)},
			{"Average Memory Usage", fmt.Sprintf("%.1f%%", avgMem), memStatus(avgMem)},
			{"Average Workflow Time", fmt.Sprintf("%.2fs", avgWorkflowTime), "‚è±Ô∏è Avg Duration"},
			{"Run Duration", fmt.Sprintf("%ds", elapsed), "‚úÖ Completed"},
		}).Render()

	// Save summary to file
	summaryText := generateSummaryText(finalStarted, finalCompleted, finalFailed, 0, avgCPU, avgMem, avgWorkflowTime, float64(elapsed))
	summaryFile := filepath.Join("logs", fmt.Sprintf("summary_%d.txt", os.Getpid()))
	if err := os.WriteFile(summaryFile, []byte(summaryText), 0644); err != nil {
		pterm.Warning.Printf("Failed to save summary: %v\n", err)
	}

	storeLog("Workflow completed")
	updateMetricsFile()
}

func clear() {
	print("\033[H\033[2J")
}

func getNextAvailablePort() int {
	mutex.Lock()
	defer mutex.Unlock()
	const maxPort = 65000
	checked := 0
	for {
		lastUsedPort++
		if lastUsedPort > maxPort {
			lastUsedPort = startPort
		}
		if isPortAvailable(lastUsedPort) {
			return lastUsedPort
		}
		checked++
		if connect3270.Verbose {
			pterm.Warning.Printf("Port %d is taken - port party‚Äôs full!\n", lastUsedPort)
		}
		if checked >= (maxPort - startPort + 1) {
			mutex.Unlock()
			time.Sleep(100 * time.Millisecond)
			mutex.Lock()
			checked = 0
		}
	}
}

func isPortAvailable(port int) bool {
	addr := ":" + strconv.Itoa(port)
	ln, err := net.Listen("tcp", addr)
	if err != nil {
		if connect3270.Verbose {
			pterm.Info.Printf("Port %d in use - next contestant please!\n", port)
		}
		return false
	}
	ln.Close()
	return true
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

func max(a, b int) int {
	if a > b {
		return a
	}
	return b
}

func validateConfiguration(config *Configuration) error {
	if connect3270.Verbose {
		pterm.Info.Println("Validating config - let‚Äôs see if it‚Äôs naughty or nice!")
	}
	if config.Host == "" {
		return fmt.Errorf("host is empty - where‚Äôs the party at?")
	}
	if config.Port <= 0 {
		return fmt.Errorf("port is invalid - ports cant be negative silly")
	}
	if config.Delay < 0 {
		return fmt.Errorf("Delay must be zero or positive")
	}
	if config.OutputFilePath == "" {
		hasScreenGrab := false
		for _, step := range config.Steps {
			if step.Type == "AsciiScreenGrab" {
				hasScreenGrab = true
				break
			}
		}
		if hasScreenGrab {
			return fmt.Errorf("output file path is empty - screen grab needs a home")
		}
	}

	for _, step := range config.Steps {
		// Allow steps that do not require additional configuration.
		if step.Type == "Connect" ||
			step.Type == "AsciiScreenGrab" ||
			step.Type == "PressEnter" ||
			step.Type == "PressTab" ||
			step.Type == "WaitForField" ||
			step.Type == "Disconnect" ||
			step.Type == "HumanDelay" ||
			(strings.HasPrefix(step.Type, "PressPF")) {
			if step.Type == "HumanDelay" {
				if step.Delay <= 0 {
					return fmt.Errorf("HumanDelay step needs a positive Delay value")
				}
			}
			continue
		}
		// Steps that require coordinates and text.
		if step.Type == "CheckValue" || step.Type == "FillString" {
			if step.Coordinates.Row == 0 || step.Coordinates.Column == 0 {
				return fmt.Errorf("coords missing in %s step - lost in space", step.Type)
			}
			if step.Text == "" {
				return fmt.Errorf("text empty in %s step - cat got your tongue?", step.Type)
			}
			continue
		}
		// Unknown step type.
		return fmt.Errorf("unknown step type: %s - what‚Äôs this nonsense?", step.Type)
	}
	return nil
}

func runDashboard() {

	// Serve embedded static files
	staticFiles, err := fs.Sub(dashboardTemplateFS, "templates/static")
	if err != nil {
		pterm.Error.Println("Failed to load embedded static files:", err)
		return
	}
	http.Handle("/static/", http.StripPrefix("/static/", http.FileServer(http.FS(staticFiles))))

	// Register the start-process endpoint
	http.HandleFunc("/start-process", startProcessHandler)
	http.HandleFunc("/kill", killProcessHandler) // register kill endpoint
	http.HandleFunc("/test-connection", testConnectionHandler)

	addr := fmt.Sprintf("localhost:%d", dashboardPort) // Bind to localhost
	listener, err := net.Listen("tcp", addr)
	if err != nil {
		pterm.Warning.Printf("Dashboard already vibing on port %d - skipping the encore!\n", dashboardPort)
		go func() {
			for {
				updateMetricsFile()
				time.Sleep(2 * time.Second)
			}
		}()
		return
	}
	dashboardStarted = true
	//openDashboardEmbedded()
	spinner, _ := pterm.DefaultSpinner.WithRemoveWhenDone(true).Start("Cleaning up old metrics - sweeping the floor!")
	dashboardDir := dashboardMetricsDir()
	files, err := filepath.Glob(filepath.Join(dashboardDir, "metrics_*.json"))
	if err != nil {
		spinner.Warning("Error listing old metrics - file system‚Äôs trolling:", err)
	} else {
		for _, f := range files {
			if err := os.Remove(f); err != nil {
				pterm.Warning.Printf("Failed to yeet old metrics file %s: %v\n", f, err)
			} else {
				//pterm.Info.Printf("Old metrics file %s gone - poof!\n", f)
			}
		}
	}
	logFiles, err := filepath.Glob(filepath.Join("logs", "logs_*.json"))
	if err == nil {
		for _, lf := range logFiles {
			if err := os.Remove(lf); err != nil {
				//pterm.Warning.Printf("Failed to nuke old log file %s: %v\n", lf, err)
			} else {
				//pterm.Info.Printf("Old log file %s vaporized!\n", lf)
			}
		}
	}
	spinner.Success("Cleanup done - dashboard‚Äôs fresh as a daisy!")

	setupConsoleHandler()
	setupTerminalConsoleHandler()
	setupWorkflowPreviewHandler()
	setupOutputPreviewHandler()
	setupSummaryHandler()
	http.HandleFunc("/dashboard", func(w http.ResponseWriter, r *http.Request) {
		// Check if the dashboardTemplate is nil
		if dashboardTemplate == nil {
			pterm.Error.Println("Dashboard template is nil. Ensure the template is loaded correctly.")
			http.Error(w, "Internal Server Error: Dashboard template not loaded", http.StatusInternalServerError)
			return
		}

		metricsList, extendedList := readDashboardMetrics(dashboardDir)
		metricsJSON, _ := json.Marshal(metricsList)
		autoRefresh := r.URL.Query().Get("autoRefresh")
		refreshPeriod := r.URL.Query().Get("refreshPeriod")
		if refreshPeriod == "" {
			refreshPeriod = "5"
		}
		checked := ""
		if autoRefresh == "true" {
			checked = "checked"
		}
		sel1, sel5, sel10, sel15, sel30 := "", "", "", "", ""
		switch refreshPeriod {
		case "1":
			sel1 = "selected"
		case "5":
			sel5 = "selected"
		case "10":
			sel10 = "selected"
		case "15":
			sel15 = "selected"
		case "30":
			sel30 = "selected"
		}
		agg := aggregateExtendedMetrics(extendedList)
		extendedJSON, err := json.Marshal(extendedList)
		if err != nil {
			pterm.Error.Printf("Error marshaling extended metrics: %v\n", err)
		}

		data := struct {
			ActiveWorkflows                 int
			TotalWorkflowsStarted           int64
			TotalWorkflowsCompleted         int64
			TotalWorkflowsFailed            int64
			Checked                         string
			Sel1, Sel5, Sel10, Sel15, Sel30 string
			Year                            int
			AutoRefreshEnabled              bool
			RefreshPeriod                   string
			MetricsJSON                     string
			ExtendedMetricsList             []ExtendedMetrics
			ExtendedJSON                    string
			Version                         string
		}{
			ActiveWorkflows:         agg.ActiveWorkflows,
			TotalWorkflowsStarted:   agg.TotalWorkflowsStarted,
			TotalWorkflowsCompleted: agg.TotalWorkflowsCompleted,
			TotalWorkflowsFailed:    agg.TotalWorkflowsFailed,
			Checked:                 checked,
			Sel1:                    sel1,
			Sel5:                    sel5,
			Sel10:                   sel10,
			Sel15:                   sel15,
			Sel30:                   sel30,
			Year:                    time.Now().Year(),
			AutoRefreshEnabled:      autoRefresh == "true",
			RefreshPeriod:           refreshPeriod,
			MetricsJSON:             string(metricsJSON),
			ExtendedMetricsList:     extendedList,
			ExtendedJSON:            string(extendedJSON),
			Version:                 version, // Holds the value of the const `version`
		}
		// Use a buffer to write the template output first, then write it all at once
		// This prevents partial responses from being written if the connection closes
		var buf bytes.Buffer
		if err := dashboardTemplate.Execute(&buf, data); err != nil {
			pterm.Error.Printf("Dashboard template execution failed - HTML's throwing a tantrum: %v\n", err)
			// Only try to send error if we haven't written to the response yet
			http.Error(w, "Internal Server Error", http.StatusInternalServerError)
			return
		}

		// Write the complete response at once
		if _, err := buf.WriteTo(w); err != nil {
			// Connection was closed by client, just log it without the scary message
			// This is normal when browser refreshes or navigates away
			if connect3270.Verbose {
				pterm.Warning.Printf("Client closed connection during dashboard response: %v\n", err)
			}
		}
	})
	http.HandleFunc("/dashboard/data", func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Cache-Control", "no-store")
		_, extendedList := readDashboardMetrics(dashboardDir)

		// Prefer live processes for UI stats; fall back to latest snapshot if nothing running.
		filtered := make([]ExtendedMetrics, 0, len(extendedList))
		for _, m := range extendedList {
			if m.IsRunning {
				filtered = append(filtered, m)
			}
		}
		if len(filtered) == 0 {
			filtered = extendedList
		}

		payload := struct {
			AggregatedMetrics Metrics           `json:"aggregated"`
			ExtendedMetrics   []ExtendedMetrics `json:"extendedMetrics"`
			Timestamp         int64             `json:"timestamp"`
		}{
			AggregatedMetrics: aggregateExtendedMetrics(filtered),
			ExtendedMetrics:   filtered,
			Timestamp:         time.Now().Unix(),
		}
		w.Header().Set("Content-Type", "application/json")
		if err := json.NewEncoder(w).Encode(payload); err != nil {
			pterm.Warning.Printf("Failed to marshal dashboard data response: %v\n", err)
		}
	})
	pterm.Info.Printf("Dashboard live at %s - check it out!\n", pterm.FgBlue.Sprintf("http://localhost:%d/dashboard", dashboardPort))
	pterm.Println()
	go func() {
		for {
			updateMetricsFile()
			time.Sleep(2 * time.Second)
		}
	}()
	if err := http.Serve(listener, nil); err != nil {
		pterm.Error.Printf("Dashboard server crashed - send a medic: %v\n", err)
	}
}

type Metrics struct {
	PID                     int       `json:"pid"`
	ActiveWorkflows         int       `json:"activeWorkflows"`
	TotalWorkflowsStarted   int64     `json:"totalWorkflowsStarted"`
	TotalWorkflowsCompleted int64     `json:"totalWorkflowsCompleted"`
	TotalWorkflowsFailed    int64     `json:"totalWorkflowsFailed"`
	Durations               []float64 `json:"durations"`
	CPUUsage                []float64 `json:"cpuUsage"`
	MemoryUsage             []float64 `json:"memoryUsage"`
	Params                  string    `json:"params"`
	RuntimeDuration         int       `json:"runtimeDuration"`
	StartTimestamp          int64     `json:"startTimestamp"`
	ConfigFilePath          string    `json:"configFilePath,omitempty"`
	OutputFilePath          string    `json:"outputFilePath,omitempty"`
}

type ExtendedMetrics struct {
	Metrics
	Status    string `json:"status"`
	TimeLeft  int64  `json:"timeLeft"`
	IsRunning bool   `json:"isRunning"`
}

func isProcessRunning(pid int) bool {
	if pid <= 0 {
		return false
	}
	if runtime.GOOS == "windows" {
		cmd := exec.Command("tasklist", "/FI", fmt.Sprintf("PID eq %d", pid))
		output, err := cmd.Output()
		if err != nil {
			pterm.Warning.Printf("Failed to query tasklist for pid %d: %v\n", pid, err)
			return true
		}
		return bytes.Contains(output, []byte(fmt.Sprintf("%d", pid)))
	}
	proc, err := os.FindProcess(pid)
	if err != nil {
		return false
	}
	if err := proc.Signal(syscall.Signal(0)); err != nil {
		return false
	}
	return true
}

func shouldCleanupMetric(m ExtendedMetrics, modTime time.Time) bool {
	if m.IsRunning || m.Status != "Killed" {
		return false
	}
	// Only clean up long-dead "killed" entries to avoid nuking live stats.
	if modTime.IsZero() {
		return false
	}
	return time.Since(modTime) > 10*time.Minute
}

func cleanupProcessArtifacts(pid int, metricsFile string) {
	if metricsFile != "" {
		if err := os.Remove(metricsFile); err != nil && !os.IsNotExist(err) {
			pterm.Warning.Printf("Failed to remove stale metrics file %s for pid %d: %v\n", metricsFile, pid, err)
		}
	}
	logFilePath := filepath.Join("logs", fmt.Sprintf("logs_%d.json", pid))
	if err := os.Remove(logFilePath); err != nil && !os.IsNotExist(err) {
		pterm.Warning.Printf("Failed to remove stale log file %s for pid %d: %v\n", logFilePath, pid, err)
	}
}

func dashboardMetricsDir() string {
	configDir, err := os.UserConfigDir()
	if err != nil {
		pterm.Warning.Printf("User config directory unavailable, defaulting to local dashboard folder: %v\n", err)
		return filepath.Join(".", "dashboard")
	}
	return filepath.Join(configDir, "3270Connect", "dashboard")
}

func readDashboardMetrics(baseDir string) ([]Metrics, []ExtendedMetrics) {
	files, err := filepath.Glob(filepath.Join(baseDir, "metrics_*.json"))
	if err != nil {
		pterm.Warning.Printf("Error listing metrics files from %s: %v\n", baseDir, err)
		return nil, nil
	}
	var metricsList []Metrics
	var extendedList []ExtendedMetrics
	for _, f := range files {
		fi, err := os.Stat(f)
		if err != nil {
			if os.IsNotExist(err) {
				continue
			}
			pterm.Warning.Printf("Stat on metrics file %s failed: %v\n", f, err)
			continue
		}

		data, err := ioutil.ReadFile(f)
		if err != nil {
			if os.IsNotExist(err) {
				continue
			}
			pterm.Warning.Printf("Error reading metrics file %s: %v\n", f, err)
			continue
		}
		var m Metrics
		if err := json.Unmarshal(data, &m); err != nil {
			pterm.Warning.Printf("Error unmarshaling metrics %s: %v\n", f, err)
			continue
		}
		extendedMetric := m.extend()
		if shouldCleanupMetric(extendedMetric, fi.ModTime()) {
			cleanupProcessArtifacts(extendedMetric.PID, f)
			continue
		}
		metricsList = append(metricsList, m)
		extendedList = append(extendedList, extendedMetric)
	}
	return metricsList, extendedList
}

func aggregateExtendedMetrics(metrics []ExtendedMetrics) Metrics {
	var agg Metrics
	for _, metric := range metrics {
		agg.ActiveWorkflows += metric.ActiveWorkflows
		agg.TotalWorkflowsStarted += metric.TotalWorkflowsStarted
		agg.TotalWorkflowsCompleted += metric.TotalWorkflowsCompleted
		agg.TotalWorkflowsFailed += metric.TotalWorkflowsFailed
		agg.Durations = append(agg.Durations, metric.Durations...)
		agg.CPUUsage = append(agg.CPUUsage, metric.CPUUsage...)
		agg.MemoryUsage = append(agg.MemoryUsage, metric.MemoryUsage...)
	}
	return agg
}

func updateMetricsFile() {
	metricsMutex.Lock()
	cpuCopy := make([]float64, len(cpuHistory))
	copy(cpuCopy, cpuHistory)
	memCopy := make([]float64, len(memHistory))
	copy(memCopy, memHistory)
	metricsMutex.Unlock()

	timingsMutex.Lock()
	durationsCopy := make([]float64, len(workflowDurations))
	copy(durationsCopy, workflowDurations)
	timingsMutex.Unlock()

	// Fallback sampling in case monitorSystemUsage hasn't populated history yet.
	if len(cpuCopy) == 0 {
		if cpuPercents, err := cpu.Percent(0, false); err == nil && len(cpuPercents) > 0 {
			cpuCopy = append(cpuCopy, cpuPercents[0])
		}
	}
	if len(memCopy) == 0 {
		if memStats, err := mem.VirtualMemory(); err == nil && memStats != nil {
			memCopy = append(memCopy, memStats.UsedPercent)
		}
	}

	pid := os.Getpid()
	args := os.Args[1:]
	parameters := strings.Join(args, " ")
	configPath := metricsConfigFilePath
	if configPath == "" {
		configPath = configFile
	}
	if configPath != "" {
		if absPath, err := filepath.Abs(configPath); err == nil {
			configPath = absPath
		}
	}
	outputPath := metricsOutputFilePath
	if outputPath != "" {
		if absPath, err := filepath.Abs(outputPath); err == nil {
			outputPath = absPath
		}
	}
	metrics := Metrics{
		PID:                     pid,
		ActiveWorkflows:         getActiveWorkflows(),
		TotalWorkflowsStarted:   atomic.LoadInt64(&totalWorkflowsStarted),
		TotalWorkflowsCompleted: atomic.LoadInt64(&totalWorkflowsCompleted),
		TotalWorkflowsFailed:    atomic.LoadInt64(&totalWorkflowsFailed),
		Durations:               durationsCopy,
		CPUUsage:                cpuCopy,
		MemoryUsage:             memCopy,
		Params:                  parameters,
		RuntimeDuration:         runtimeDuration,
		StartTimestamp: func() int64 {
			if programStart.IsZero() {
				return time.Now().Unix()
			}
			return programStart.Unix()
		}(),
		ConfigFilePath: configPath,
		OutputFilePath: outputPath,
	}

	// Process extended metrics by using the extend() method on metrics.
	extendedMetrics := metrics.extend()

	data, err := json.Marshal(extendedMetrics)
	if err != nil {
		pterm.Warning.Printf("Extended metrics marshaling failed for pid %d - JSON‚Äôs sulking: %v\n", pid, err)
		return
	}
	dashboardDir := dashboardMetricsDir()
	os.MkdirAll(dashboardDir, 0755)
	filePath := filepath.Join(dashboardDir, fmt.Sprintf("metrics_%d.json", pid))
	if err := ioutil.WriteFile(filePath, data, 0644); err != nil {
		pterm.Warning.Printf("Metrics file write failed for pid %d - disk‚Äôs grumpy: %v\n", pid, err)
	}
	maybeCleanupDashboardArtifacts()
}

func aggregateMetrics() Metrics {
	dashboardDir, err := os.UserConfigDir()
	if err != nil {
		pterm.Warning.Println("User config dir fetch failed:", err)
		dashboardDir = filepath.Join(".", "dashboard")
	} else {
		dashboardDir = filepath.Join(dashboardDir, "3270Connect", "dashboard")
	}
	files, err := filepath.Glob(filepath.Join(dashboardDir, "metrics_*.json"))
	if err != nil {
		pterm.Warning.Println("Metrics files listing failed:", err)
		return Metrics{}
	}
	var agg Metrics
	for _, f := range files {
		// Check if file exists before attempting to read it
		fi, err := os.Stat(f)
		if err != nil {
			if os.IsNotExist(err) {
				continue
			}
			pterm.Warning.Printf("Stat on metrics file %s failed: %v\n", f, err)
			continue
		}

		data, err := ioutil.ReadFile(f)
		if err != nil {
			// File may have been deleted between Stat and ReadFile, silently continue
			if os.IsNotExist(err) {
				continue
			}
			pterm.Warning.Printf("Reading file %s failed: %v\n", f, err)
			continue
		}
		var m Metrics
		if err := json.Unmarshal(data, &m); err != nil {
			pterm.Warning.Printf("Unmarshaling file %s failed: %v\n", f, err)
			continue
		}
		extendedMetric := m.extend()
		if shouldCleanupMetric(extendedMetric, fi.ModTime()) {
			cleanupProcessArtifacts(extendedMetric.PID, f)
			continue
		}
		agg.TotalWorkflowsStarted += extendedMetric.TotalWorkflowsStarted
		agg.TotalWorkflowsCompleted += extendedMetric.TotalWorkflowsCompleted
		agg.TotalWorkflowsFailed += extendedMetric.TotalWorkflowsFailed
		agg.ActiveWorkflows += extendedMetric.ActiveWorkflows
		agg.Durations = append(agg.Durations, extendedMetric.Durations...)
		agg.CPUUsage = append(agg.CPUUsage, extendedMetric.CPUUsage...)
		agg.MemoryUsage = append(agg.MemoryUsage, extendedMetric.MemoryUsage...)
		agg.RuntimeDuration = extendedMetric.RuntimeDuration // Keep last or overwrite
		agg.StartTimestamp = extendedMetric.StartTimestamp
	}
	return agg
}

func (m Metrics) extend() ExtendedMetrics {
	timeElapsed := time.Now().Unix() - m.StartTimestamp
	timeLeft := int64(m.RuntimeDuration) - timeElapsed
	if timeLeft < 0 {
		timeLeft = 0
	}
	status := "Running" // Default status for missing or incomplete metrics
	isRunning := isProcessRunning(m.PID)
	completedOrFailed := m.TotalWorkflowsCompleted + m.TotalWorkflowsFailed
	allWorkflowsAccounted := m.TotalWorkflowsStarted > 0 &&
		completedOrFailed >= m.TotalWorkflowsStarted &&
		m.ActiveWorkflows == 0
	if m.RuntimeDuration > 0 && timeLeft == 0 && (m.Params != "" && !strings.Contains(m.Params, "-runApp")) {
		status = "Ended"
	}
	if !isRunning {
		switch {
		case allWorkflowsAccounted:
			status = "Ended"
		case status != "Ended":
			status = "Killed"
		}
	}

	return ExtendedMetrics{
		Metrics:   m,
		Status:    status,
		TimeLeft:  timeLeft,
		IsRunning: isRunning,
	}
}

func monitorSystemUsage() {
	ticker := time.NewTicker(2 * time.Second)
	defer ticker.Stop()

	for range ticker.C {
		cpuPercents, err := cpu.Percent(0, false)
		if err == nil && len(cpuPercents) > 0 {
			var sum float64
			for _, p := range cpuPercents {
				sum += p
			}
			overall := sum / float64(len(cpuPercents))
			metricsMutex.Lock()
			appendLimitedFloat(&cpuHistory, overall, cpuHistoryLimit)
			totalCPUUsage += overall
			totalCPUSamples++
			lastCPUUsage = overall
			metricsMutex.Unlock()
		}
		memStats, err := mem.VirtualMemory()
		if err == nil && memStats != nil {
			metricsMutex.Lock()
			appendLimitedFloat(&memHistory, memStats.UsedPercent, memHistoryLimit)
			totalMemUsage += memStats.UsedPercent
			totalMemSamples++
			lastMemUsage = memStats.UsedPercent
			metricsMutex.Unlock()
		}

		// Keep dashboard system interface metrics fresh even if the dashboard update loop isn't running.
		updateMetricsFile()
	}
}

func setupConsoleHandler() {
	http.HandleFunc("/console", func(w http.ResponseWriter, r *http.Request) {
		pidFilter := r.URL.Query().Get("pid")
		var filtered []LogEntry
		if pidFilter != "" {
			logFilePath := filepath.Join("logs", fmt.Sprintf("logs_%s.json", pidFilter))
			file, err := os.Open(logFilePath)
			if err != nil {
				if os.IsNotExist(err) {
					w.Header().Set("Content-Type", "application/json")
					w.WriteHeader(http.StatusOK)
					json.NewEncoder(w).Encode([]LogEntry{})
					return
				}
				pterm.Warning.Printf("Log file opening failed for PID %s: %v\n", pidFilter, err)
				http.Error(w, "Error opening log file", http.StatusInternalServerError)
				return
			}
			defer file.Close()
			decoder := json.NewDecoder(file)
			for {
				var logEntry LogEntry
				if err := decoder.Decode(&logEntry); err != nil {
					if err == io.EOF {
						break
					}
					pterm.Warning.Println("Log entry decoding failed:", err)
					http.Error(w, "Error decoding log entry", http.StatusInternalServerError)
					return
				}
				filtered = append(filtered, logEntry)
			}
		} else {
			logFiles, err := filepath.Glob(filepath.Join("logs", "logs_*.json"))
			if err == nil {
				for _, lf := range logFiles {
					file, err := os.Open(lf)
					if err != nil {
						pterm.Warning.Printf("Log file %s opening failed: %v\n", lf, err)
						continue
					}
					func() {
						defer file.Close()
						decoder := json.NewDecoder(file)
						for {
							var logEntry LogEntry
							if err := decoder.Decode(&logEntry); err != nil {
								if err == io.EOF {
									break
								}
								pterm.Warning.Println("Log entry decoding failed:", err)
								break // Exit decoding loop on error
							}
							filtered = append(filtered, logEntry)
						}
					}()
				}
			}
		}
		sort.Slice(filtered, func(i, j int) bool {
			return filtered[i].Timestamp.After(filtered[j].Timestamp)
		})
		w.Header().Set("Content-Type", "application/json")
		w.WriteHeader(http.StatusOK)
		json.NewEncoder(w).Encode(filtered)
	})
}

func setupTerminalConsoleHandler() {
	http.HandleFunc("/terminal-console", func(w http.ResponseWriter, r *http.Request) {
		pidFilter := r.URL.Query().Get("pid")
		var filtered []LogEntry
		if pidFilter != "" {
			logFilePath := filepath.Join("logs", fmt.Sprintf("logs_%s.json", pidFilter))
			file, err := os.Open(logFilePath)
			if err != nil {
				if os.IsNotExist(err) {
					w.Header().Set("Content-Type", "text/plain")
					w.WriteHeader(http.StatusOK)
					return
				}
				pterm.Warning.Printf("Log file opening failed for PID %s: %v\n", pidFilter, err)
				http.Error(w, "Error opening log file", http.StatusInternalServerError)
				return
			}
			defer file.Close()
			decoder := json.NewDecoder(file)
			for {
				var logEntry LogEntry
				if err := decoder.Decode(&logEntry); err != nil {
					if err == io.EOF {
						break
					}
					pterm.Warning.Println("Log entry decoding failed:", err)
					http.Error(w, "Error decoding log entry", http.StatusInternalServerError)
					return
				}
				filtered = append(filtered, logEntry)
			}
		} else {
			logFiles, err := filepath.Glob(filepath.Join("logs", "logs_*.json"))
			if err == nil {
				for _, lf := range logFiles {
					file, err := os.Open(lf)
					if err != nil {
						pterm.Warning.Printf("Log file %s opening failed: %v\n", lf, err)
						continue
					}
					func() {
						defer file.Close()
						decoder := json.NewDecoder(file)
						for {
							var logEntry LogEntry
							if err := decoder.Decode(&logEntry); err != nil {
								if err == io.EOF {
									break
								}
								pterm.Warning.Println("Log entry decoding failed:", err)
								break // Exit decoding loop on error
							}
							filtered = append(filtered, logEntry)
						}
					}()
				}
			}
		}
		sort.Slice(filtered, func(i, j int) bool {
			return filtered[i].Timestamp.After(filtered[j].Timestamp)
		})
		w.Header().Set("Content-Type", "text/plain")
		w.WriteHeader(http.StatusOK)
		for _, entry := range filtered {
			w.Write([]byte(fmt.Sprintf("%s\n", entry.Log)))
		}
	})
}

func setupWorkflowPreviewHandler() {
	http.HandleFunc("/dashboard/workflow", func(w http.ResponseWriter, r *http.Request) {
		pid := r.URL.Query().Get("pid")
		metric, err := loadExtendedMetricByPID(pid)
		if err != nil {
			if os.IsNotExist(err) {
				http.Error(w, "No metrics file found for PID "+pid, http.StatusNotFound)
			} else {
				http.Error(w, "Unable to load metrics: "+err.Error(), http.StatusInternalServerError)
			}
			return
		}
		configPath := metric.ConfigFilePath
		if configPath == "" {
			http.Error(w, "Workflow configuration is not available for PID "+pid, http.StatusNotFound)
			return
		}
		file, err := os.Open(configPath)
		if err != nil {
			if os.IsNotExist(err) {
				http.Error(w, "Workflow file not found: "+configPath, http.StatusNotFound)
			} else {
				http.Error(w, "Failed to open workflow file: "+err.Error(), http.StatusInternalServerError)
			}
			return
		}
		defer file.Close()
		w.Header().Set("Content-Type", "application/json")
		w.Header().Set("Cache-Control", "no-store")
		w.Header().Set("X-Content-Type-Options", "nosniff")
		if _, err := io.Copy(w, file); err != nil {
			http.Error(w, "Failed to stream workflow file: "+err.Error(), http.StatusInternalServerError)
		}
	})
}

func setupOutputPreviewHandler() {
	http.HandleFunc("/dashboard/output", func(w http.ResponseWriter, r *http.Request) {
		pid := r.URL.Query().Get("pid")
		metric, err := loadExtendedMetricByPID(pid)
		if err != nil {
			if os.IsNotExist(err) {
				http.Error(w, "No metrics file found for PID "+pid, http.StatusNotFound)
			} else {
				http.Error(w, "Unable to load metrics: "+err.Error(), http.StatusInternalServerError)
			}
			return
		}
		outputPath := metric.OutputFilePath
		if outputPath == "" {
			http.Error(w, "Output file path is not configured for PID "+pid, http.StatusNotFound)
			return
		}
		file, err := os.Open(outputPath)
		if err != nil {
			if os.IsNotExist(err) {
				http.Error(w, "Output file not found: "+outputPath, http.StatusNotFound)
			} else {
				http.Error(w, "Failed to open output file: "+err.Error(), http.StatusInternalServerError)
			}
			return
		}
		defer file.Close()
		w.Header().Set("Content-Type", "text/html; charset=utf-8")
		w.Header().Set("Cache-Control", "no-store")
		w.Header().Set("X-Content-Type-Options", "nosniff")
		if _, err := io.Copy(w, file); err != nil {
			http.Error(w, "Failed to stream output file: "+err.Error(), http.StatusInternalServerError)
		}
	})
}

func setupSummaryHandler() {
	http.HandleFunc("/dashboard/summary", func(w http.ResponseWriter, r *http.Request) {
		pid := r.URL.Query().Get("pid")
		summaryFile := filepath.Join("logs", fmt.Sprintf("summary_%s.txt", pid))
		file, err := os.Open(summaryFile)
		if err != nil {
			http.Error(w, "Summary not found", http.StatusNotFound)
			return
		}
		defer file.Close()
		w.Header().Set("Content-Type", "text/plain")
		io.Copy(w, file)
	})
}

func loadExtendedMetricByPID(pid string) (*ExtendedMetrics, error) {
	if pid == "" {
		return nil, fmt.Errorf("missing pid")
	}
	dir := dashboardMetricsDir()
	filePath := filepath.Join(dir, fmt.Sprintf("metrics_%s.json", pid))
	data, err := os.ReadFile(filePath)
	if err != nil {
		return nil, err
	}
	var metric ExtendedMetrics
	if err := json.Unmarshal(data, &metric); err != nil {
		return nil, err
	}
	return &metric, nil
}

func getActiveWorkflows() int {
	mutex.Lock()
	defer mutex.Unlock()
	return activeWorkflows
}

func showErrors() {
	errorMutex.Lock()
	defer errorMutex.Unlock()
	if len(errorList) == 0 {
		pterm.Info.Println("No errors encountered during the workflows.")
		return
	}

	pterm.Error.Println("Errors Summary:")
	errorCount := make(map[string]int)
	for _, err := range errorList {
		errorCount[err.Error()]++
	}

	for errMsg, count := range errorCount {
		pterm.Error.Printf("%d occurrence(s) of: %s\n", count, errMsg)
	}
}

func handleError(err error, message string) error {
	pterm.Error.Println(message)
	addError(err)
	return err
}

func addError(err error) {
	errorMutex.Lock()
	defer errorMutex.Unlock()
	errorList = append(errorList, err)
}

// Add a new endpoint to handle the process initiation request
func startProcessHandler(w http.ResponseWriter, r *http.Request) {
	storeLog("Received start process request")
	if r.Method != http.MethodPost {
		storeLog("Invalid request method for start process")
		http.Error(w, "Invalid request method", http.StatusMethodNotAllowed)
		return
	}

	// Check for sample app parameters
	runApp := r.FormValue("runApp")
	if runApp != "" {
		storeLog("Sample app mode detected")
		runAppPort := r.FormValue("runAppPort")
		// Construct command for sample app mode
		executablePath := getExecutablePath()
		command := fmt.Sprintf("%s -runApp %s -runApp-port %s", executablePath, runApp, runAppPort)
		go func() {
			pterm.Info.Printf("Executing sample app command: %s\n", command)
			storeLog("Executing sample app command: " + command)
			// Adjust for OS differences if needed
			commandParts := strings.Fields(command)
			executable := commandParts[0]
			args := commandParts[1:]

			cmd := exec.Command(executable, args...)
			cmd.Stdout = os.Stdout
			cmd.Stderr = os.Stderr
			if err := cmd.Run(); err != nil {
				pterm.Error.Printf("Failed to execute sample app command: %v\n", err)
			}
		}()
		storeLog("Sample app started successfully")
		w.WriteHeader(http.StatusOK)
		w.Write([]byte("Sample app started successfully"))
		return
	}

	storeLog("Processing normal workflow")
	// Normal workflow: retrieve the uploaded file
	if err := r.ParseMultipartForm(10 << 20); err != nil { // 10 MB max file size
		http.Error(w, "Failed to parse form data", http.StatusBadRequest)
		return
	}

	file, handler, err := r.FormFile("configFile")
	if err != nil {
		http.Error(w, "Failed to retrieve file", http.StatusBadRequest)
		return
	}
	defer file.Close()

	fileBytes, err := io.ReadAll(file)
	if err != nil {
		http.Error(w, "Failed to read configuration file", http.StatusInternalServerError)
		return
	}

	var config Configuration
	if err := json.Unmarshal(fileBytes, &config); err != nil {
		storeLog("Failed to parse configuration JSON: " + err.Error())
		http.Error(w, "Invalid configuration file", http.StatusBadRequest)
		return
	}

	if override := strings.TrimSpace(r.FormValue("overrideHost")); override != "" {
		config.Host = override
	}
	if override := strings.TrimSpace(r.FormValue("overridePort")); override != "" {
		portValue, convErr := strconv.Atoi(override)
		if convErr != nil {
			http.Error(w, "Invalid port override", http.StatusBadRequest)
			return
		}
		config.Port = portValue
	}
	if override := strings.TrimSpace(r.FormValue("overrideOutputFilePath")); override != "" {
		config.OutputFilePath = override
	}
	if override := strings.TrimSpace(r.FormValue("overrideRampUpBatchSize")); override != "" {
		batchValue, convErr := strconv.Atoi(override)
		if convErr != nil {
			http.Error(w, "Invalid ramp up batch size override", http.StatusBadRequest)
			return
		}
		config.RampUpBatchSize = batchValue
	}
	if override := strings.TrimSpace(r.FormValue("overrideRampUpDelay")); override != "" {
		delayValue, convErr := strconv.ParseFloat(override, 64)
		if convErr != nil {
			http.Error(w, "Invalid ramp up delay override", http.StatusBadRequest)
			return
		}
		config.RampUpDelay = delayValue
	}

	if err := validateConfiguration(&config); err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}

	updatedJSON, err := json.MarshalIndent(config, "", "  ")
	if err != nil {
		http.Error(w, "Failed to serialize configuration", http.StatusInternalServerError)
		return
	}

	tempFilePath := filepath.Join(os.TempDir(), handler.Filename)
	if err := os.WriteFile(tempFilePath, updatedJSON, 0644); err != nil {
		http.Error(w, "Failed to save file", http.StatusInternalServerError)
		return
	}

	// Retrieve the injection configuration file (optional)
	var injectionConfigPath string
	injectionFile, injectionHandler, err := r.FormFile("injectionConfig")
	if err == nil {
		defer injectionFile.Close()
		injectionConfigPath = filepath.Join(os.TempDir(), injectionHandler.Filename)
		injectionTempFile, err := os.Create(injectionConfigPath)
		if err != nil {
			http.Error(w, "Failed to save injection configuration file", http.StatusInternalServerError)
			return
		}
		defer injectionTempFile.Close()

		if _, err := io.Copy(injectionTempFile, injectionFile); err != nil {
			http.Error(w, "Failed to save injection configuration file", http.StatusInternalServerError)
			return
		}
	}

	// Retrieve other form fields
	concurrent := r.FormValue("concurrent")
	runtime := r.FormValue("runtime")
	startPort := r.FormValue("startPort")
	headless := r.FormValue("headless") == "on" // use "on" for checked
	tokenValue := strings.TrimSpace(r.FormValue("token"))

	commandArgs := []string{
		getExecutablePath(),
		"-config", tempFilePath,
		"-concurrent", concurrent,
		"-runtime", runtime,
		"-startPort", startPort,
	}
	if headless {
		commandArgs = append(commandArgs, "-headless")
	}
	if injectionConfigPath != "" {
		commandArgs = append(commandArgs, "-injectionConfig", injectionConfigPath)
	}
	if tokenValue != "" {
		commandArgs = append(commandArgs, "-token", tokenValue)
	}

	maskedArgs := make([]string, len(commandArgs))
	copy(maskedArgs, commandArgs)
	for i := 0; i < len(maskedArgs); i++ {
		if maskedArgs[i] == "-token" && i+1 < len(maskedArgs) {
			maskedArgs[i+1] = "[REDACTED]"
		}
	}
	commandForLog := strings.Join(maskedArgs, " ")
	storeLog("Command to execute: " + commandForLog)
	go func(args []string, logCommand string) {
		pterm.Info.Printf("Executing command: %s\n", logCommand)

		cmd := exec.Command(args[0], args[1:]...)
		cmd.Stdout = os.Stdout
		cmd.Stderr = os.Stderr
		if err := cmd.Run(); err != nil {
			pterm.Error.Printf("Failed to execute command: %v\n", err)
		}
	}(commandArgs, commandForLog)
	storeLog("Process started successfully")
	w.WriteHeader(http.StatusOK)
	w.Write([]byte("Process started successfully"))
}

func testConnectionHandler(w http.ResponseWriter, r *http.Request) {
	storeLog("Received test connection request")
	if r.Method != http.MethodPost {
		http.Error(w, "Invalid request method", http.StatusMethodNotAllowed)
		return
	}

	defer r.Body.Close()
	var payload struct {
		Host string `json:"host"`
		Port int    `json:"port"`
	}

	if err := json.NewDecoder(r.Body).Decode(&payload); err != nil {
		storeLog("Failed to decode test connection payload: " + err.Error())
		http.Error(w, "Invalid request payload", http.StatusBadRequest)
		return
	}

	host := strings.TrimSpace(payload.Host)
	if host == "" {
		http.Error(w, "Host is required", http.StatusBadRequest)
		return
	}
	if payload.Port <= 0 {
		http.Error(w, "Port must be a positive integer", http.StatusBadRequest)
		return
	}

	address := net.JoinHostPort(host, strconv.Itoa(payload.Port))
	storeLog("Testing connectivity to " + address)
	conn, err := net.DialTimeout("tcp", address, 5*time.Second)
	if err != nil {
		storeLog("Connection test failed for " + address + ": " + err.Error())
		w.Header().Set("Content-Type", "application/json")
		w.WriteHeader(http.StatusBadGateway)
		json.NewEncoder(w).Encode(map[string]string{
			"status":  "error",
			"message": fmt.Sprintf("Unable to connect to %s: %v", address, err),
		})
		return
	}
	conn.Close()
	storeLog("Connection test succeeded for " + address)
	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]string{
		"status":  "ok",
		"message": fmt.Sprintf("Successfully connected to %s", address),
	})
}

func isTerminal() bool {
	fi, err := os.Stdout.Stat()
	if err != nil {
		return false
	}
	// Check if Stdout is a character device
	return (fi.Mode() & os.ModeCharDevice) != 0
}

func killProcessHandler(w http.ResponseWriter, r *http.Request) {
	storeLog("Received kill request")
	if r.Method != http.MethodPost {
		http.Error(w, "Method Not Allowed", http.StatusMethodNotAllowed)
		return
	}
	pidStr := r.URL.Query().Get("pid")
	if pidStr == "" {
		http.Error(w, "Missing PID", http.StatusBadRequest)
		return
	}
	storeLog("Attempting to kill process with PID: " + pidStr)
	pid, err := strconv.Atoi(pidStr)
	if err != nil {
		storeLog("Invalid PID: " + pidStr)
		http.Error(w, "Invalid PID", http.StatusBadRequest)
		return
	}
	proc, err := os.FindProcess(pid)
	if err != nil {
		storeLog("Process not found: " + pidStr)
		http.Error(w, "Process not found", http.StatusNotFound)
		return
	}
	if pid == os.Getpid() {
		storeLog("Attempting to kill the dashboard process itself")
		http.Error(w, "Cannot kill the dashboard process itself", http.StatusForbidden)
		return
	}
	if err := proc.Kill(); err != nil {
		storeLog("Failed to kill process gracefully, attempting hard kill for PID: " + pidStr)
		var hardKillErr error
		if runtime.GOOS == "windows" {
			hardKillErr = exec.Command("taskkill", "/PID", pidStr, "/F").Run()
		} else {
			hardKillErr = exec.Command("kill", "-9", pidStr).Run()
		}
		if hardKillErr != nil {
			storeLog("Failed to hard kill process: " + pidStr)
			http.Error(w, "Failed to kill process", http.StatusInternalServerError)
			return
		}
	}

	// Update the metrics file to reflect the "Killed" status
	updateKilledStatus(pid)

	// Force the dashboard to reload the updated metrics
	updateMetricsFile()

	storeLog("Process killed successfully PID: " + pidStr)
	w.WriteHeader(http.StatusOK)
	w.Write([]byte("Process killed successfully"))
}

func updateKilledStatus(pid int) {
	//pterm.Info.Printf("Updating killed status for process with PID %d\n", pid)
	storeLog(fmt.Sprintf("Updating killed status for process with PID %d", pid))

	dashboardDir, err := os.UserConfigDir()
	if err != nil {
		pterm.Warning.Println("Failed to get UserConfigDir, defaulting to local dashboard directory")
		dashboardDir = filepath.Join(".", "dashboard")
	} else {
		dashboardDir = filepath.Join(dashboardDir, "3270Connect", "dashboard")
	}
	metricsFile := filepath.Join(dashboardDir, fmt.Sprintf("metrics_%d.json", pid))
	//pterm.Info.Printf("Reading metrics file: %s\n", metricsFile)
	storeLog(fmt.Sprintf("Reading metrics file: %s", metricsFile))

	data, err := ioutil.ReadFile(metricsFile)
	if err != nil {
		pterm.Warning.Printf("Failed to read metrics file for PID %d: %v\n", pid, err)
		storeLog(fmt.Sprintf("Failed to read metrics file for PID %d: %v", pid, err))
		return
	}
	var metrics Metrics
	if err := json.Unmarshal(data, &metrics); err != nil {
		pterm.Warning.Printf("Failed to unmarshal metrics for PID %d: %v\n", pid, err)
		storeLog(fmt.Sprintf("Failed to unmarshal metrics for PID %d: %v", pid, err))
		return
	}

	//pterm.Info.Printf("Clearing active workflows for PID %d\n", pid)
	storeLog(fmt.Sprintf("Clearing active workflows for killed PID %d", pid))
	// Only clear active workflows - preserve execution statistics for accurate aggregation
	metrics.ActiveWorkflows = 0

	extendedMetrics := metrics.extend()
	extendedMetrics.Status = "Killed"

	updatedData, err := json.Marshal(extendedMetrics)
	if err != nil {
		pterm.Warning.Printf("Failed to marshal updated metrics for PID %d: %v\n", pid, err)
		storeLog(fmt.Sprintf("Failed to marshal updated metrics for PID %d: %v", pid, err))
		return
	}
	if err := ioutil.WriteFile(metricsFile, updatedData, 0644); err != nil {
		pterm.Warning.Printf("Failed to write updated metrics for PID %d: %v\n", pid, err)
		storeLog(fmt.Sprintf("Failed to write updated metrics for PID %d: %v", pid, err))
		return
	}
	//pterm.Info.Printf("Successfully updated metrics for PID %d to status 'Killed'\n", pid)
	storeLog(fmt.Sprintf("Successfully updated metrics for PID %d to status 'Killed'", pid))
}

func loadInjectionData(filePath string) ([]map[string]string, error) {
	data, err := os.ReadFile(filePath)
	if err != nil {
		return nil, err
	}

	var raw interface{}
	if err := json.Unmarshal(data, &raw); err != nil {
		return nil, fmt.Errorf("failed to parse injection data: %w", err)
	}

	convertEntries := func(items []interface{}) ([]map[string]string, error) {
		entries := make([]map[string]string, 0, len(items))
		for idx, item := range items {
			obj, ok := item.(map[string]interface{})
			if !ok {
				return nil, fmt.Errorf("injection entry %d must be an object", idx)
			}
			entry := make(map[string]string, len(obj))
			for key, val := range obj {
				entry[key] = fmt.Sprint(val)
			}
			entries = append(entries, entry)
		}
		if len(entries) == 0 {
			return nil, fmt.Errorf("injection data contains no entries")
		}
		return entries, nil
	}

	switch v := raw.(type) {
	case []interface{}:
		return convertEntries(v)
	case map[string]interface{}:
		// Support wrappers like {"entries": [...] } or {"data": [...]}.
		if entriesVal, ok := v["entries"]; ok {
			if arr, ok := entriesVal.([]interface{}); ok {
				return convertEntries(arr)
			}
			return nil, fmt.Errorf("injection 'entries' must be an array")
		}
		if dataVal, ok := v["data"]; ok {
			if arr, ok := dataVal.([]interface{}); ok {
				return convertEntries(arr)
			}
			return nil, fmt.Errorf("injection 'data' must be an array")
		}
		// Treat plain object as a single entry.
		entry := make(map[string]string, len(v))
		for key, val := range v {
			entry[key] = fmt.Sprint(val)
		}
		if len(entry) == 0 {
			return nil, fmt.Errorf("injection object is empty")
		}
		return []map[string]string{entry}, nil
	default:
		return nil, fmt.Errorf("unsupported injection data format")
	}
}

func injectDynamicValues(config *Configuration, injection map[string]string) *Configuration {
	newConfig := *config // Create a copy of the configuration
	newConfig.Steps = make([]Step, len(config.Steps))
	copy(newConfig.Steps, config.Steps)

	for i, step := range newConfig.Steps {
		for placeholder, value := range injection {
			if strings.Contains(step.Text, placeholder) {
				newConfig.Steps[i].Text = strings.ReplaceAll(step.Text, placeholder, value)
			}
		}
	}

	return &newConfig
}
